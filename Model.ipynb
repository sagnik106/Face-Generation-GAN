{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Flatten, Reshape, Activation, Dense, UpSampling2D, LeakyReLU, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=list()\n",
    "for i in range(1,5000):\n",
    "    a=cv2.imread(\"img_align_celeba/%06d.jpg\"%i,1)\n",
    "    a=cv2.resize(a,(a.shape[0]//2-1,a.shape[0]//2-1))\n",
    "    a=a/255.0\n",
    "    a=a.tolist()\n",
    "    images.append(a)\n",
    "images=np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(inputs, image_shape):\n",
    "    l=32\n",
    "    x=Dense((image_shape[0]//l) * (image_shape[0]//l) * 128)(inputs)\n",
    "    x=Reshape((image_shape[0]//l, image_shape[0]//l, 128))(x)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=Conv2DTranspose(filters = 512, kernel_size=7, strides=3, padding='same', activation = 'sigmoid')(x)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=Conv2DTranspose(filters = 256, kernel_size=7, strides=3, padding='same', activation = 'sigmoid')(x)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=Conv2DTranspose(filters = 128, kernel_size=7, strides=2, padding='same', activation = 'sigmoid')(x)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=Conv2DTranspose(filters = 64, kernel_size=5, strides=2, padding='same', activation = 'sigmoid')(x)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=Conv2DTranspose(filters = 32, kernel_size=5, strides=1, padding='same', activation = 'sigmoid')(x)\n",
    "    \n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    x=Conv2DTranspose(filters = 3, kernel_size=5, strides=1, padding='same', activation = 'sigmoid')(x)\n",
    "        \n",
    "    generator=Model(inputs, x)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(inputs):\n",
    "    x=inputs\n",
    "    \n",
    "    x=LeakyReLU(alpha=0.2)(x)\n",
    "    x= Conv2D(filters= 256, kernel_size=5, strides=2, padding='same')(x)\n",
    "    \n",
    "    x=LeakyReLU(alpha=0.2)(x)\n",
    "    x= Conv2D(filters= 128, kernel_size=5, strides=2, padding='same')(x)\n",
    "    \n",
    "    x=LeakyReLU(alpha=0.2)(x)\n",
    "    x= Conv2D(filters= 64, kernel_size=5, strides=2, padding='same')(x)\n",
    "    \n",
    "    x=LeakyReLU(alpha=0.2)(x)\n",
    "    x= Conv2D(filters= 32, kernel_size=5, strides=1, padding='same')(x)\n",
    "    \n",
    "    x=Flatten()(x)\n",
    "    x=Dense(32, activation= 'sigmoid')(x)\n",
    "    x=Dense(1, activation = 'sigmoid')(x)\n",
    "    \n",
    "    discriminator = Model(inputs, x)\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(latent_size):\n",
    "    input_shape=(images.shape[1],images.shape[2],images.shape[3])\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    discriminator=dis(inputs)\n",
    "    discriminator.compile(loss = 'mse', optimizer=RMSprop(lr= 2e-4, decay=6e-8), metrics = ['accuracy'])\n",
    "    \n",
    "    inputs = Input(shape=(latent_size, ))\n",
    "    generator=gen(inputs, input_shape)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    adversarial=Model(inputs, discriminator(generator(inputs)))\n",
    "    adversarial.compile(loss='mse', optimizer = RMSprop(lr=2e-4*0.5,decay=6e-8*0.5))\n",
    "    \n",
    "    models=(generator, discriminator, adversarial)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, epochs, batch_size, latent_size, save_interval=0):\n",
    "    generator, discriminator, adversarial = models\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        rand_indices = np.random.randint(0, images.shape[0], size = batch_size)\n",
    "        real = images[rand_indices]\n",
    "        noise = np.random.uniform(0, 1.0, size = [batch_size, latent_size])\n",
    "        fake = generator.predict(noise)\n",
    "        \n",
    "        x = np.concatenate((real,fake))\n",
    "        \n",
    "        y = np.ones(batch_size*2)\n",
    "        y[batch_size:]=0.0\n",
    "        y=np.reshape(y,(batch_size*2,1))\n",
    "        \n",
    "        history = discriminator.train_on_batch(x,y)\n",
    "        \n",
    "        noise = np.random.uniform(0, 1.0, size = [batch_size, latent_size])\n",
    "        y=np.ones(batch_size)\n",
    "        y=np.reshape(y,(batch_size,1))\n",
    "        \n",
    "        \"\"\"aloss, aacc =\"\"\" \n",
    "        history1 = adversarial.train_on_batch(noise, y)\n",
    "        \n",
    "        print(\"Epoch : %d, [adversarial loss: %f] [discriminator loss: %f, acc: %f]\"%(i+1, history1, history[0], history[1]))\n",
    "        \n",
    "        if save_interval!=0:\n",
    "            if (i+1)%save_interval==0:\n",
    "                noise = np.random.uniform(0, 1.0, size = [1, latent_size])\n",
    "                n=generator.predict(noise)\n",
    "                n=n[0]\n",
    "                n*=255\n",
    "                cv2.imwrite(\"%d.jpeg\"%(i+1),n)\n",
    "                print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, [adversarial loss: 0.257499] [discriminator loss: 0.268304, acc: 0.500000]\n",
      "Epoch : 2, [adversarial loss: 0.528405] [discriminator loss: 0.250813, acc: 0.718750]\n",
      "Epoch : 3, [adversarial loss: 0.021018] [discriminator loss: 0.257222, acc: 0.500000]\n",
      "Epoch : 4, [adversarial loss: 0.377892] [discriminator loss: 0.341817, acc: 0.500000]\n",
      "Epoch : 5, [adversarial loss: 0.251881] [discriminator loss: 0.255114, acc: 0.500000]\n",
      "Epoch : 6, [adversarial loss: 0.116677] [discriminator loss: 0.229809, acc: 0.500000]\n",
      "Epoch : 7, [adversarial loss: 0.232509] [discriminator loss: 0.203122, acc: 0.929688]\n",
      "Epoch : 8, [adversarial loss: 0.018372] [discriminator loss: 0.277912, acc: 0.515625]\n",
      "Epoch : 9, [adversarial loss: 0.051374] [discriminator loss: 0.240574, acc: 0.500000]\n",
      "Epoch : 10, [adversarial loss: 0.007018] [discriminator loss: 0.192509, acc: 0.632812]\n",
      "Saved!\n",
      "Epoch : 11, [adversarial loss: 0.012157] [discriminator loss: 0.210746, acc: 0.421875]\n",
      "Epoch : 12, [adversarial loss: 0.004801] [discriminator loss: 0.172987, acc: 0.804688]\n",
      "Epoch : 13, [adversarial loss: 0.004842] [discriminator loss: 0.155677, acc: 0.968750]\n",
      "Epoch : 14, [adversarial loss: 0.003075] [discriminator loss: 0.129474, acc: 0.796875]\n",
      "Epoch : 15, [adversarial loss: 0.003020] [discriminator loss: 0.183617, acc: 0.875000]\n",
      "Epoch : 16, [adversarial loss: 0.002848] [discriminator loss: 0.118995, acc: 0.929688]\n",
      "Epoch : 17, [adversarial loss: 0.002606] [discriminator loss: 0.078182, acc: 0.921875]\n",
      "Epoch : 18, [adversarial loss: 0.002611] [discriminator loss: 0.088098, acc: 0.968750]\n",
      "Epoch : 19, [adversarial loss: 0.002557] [discriminator loss: 0.117740, acc: 0.820312]\n",
      "Epoch : 20, [adversarial loss: 0.002558] [discriminator loss: 0.177866, acc: 0.867188]\n",
      "Saved!\n",
      "Epoch : 21, [adversarial loss: 0.002618] [discriminator loss: 0.132042, acc: 0.968750]\n",
      "Epoch : 22, [adversarial loss: 0.002574] [discriminator loss: 0.111256, acc: 0.859375]\n",
      "Epoch : 23, [adversarial loss: 0.002539] [discriminator loss: 0.094523, acc: 0.859375]\n",
      "Epoch : 24, [adversarial loss: 0.002531] [discriminator loss: 0.069345, acc: 0.960938]\n",
      "Epoch : 25, [adversarial loss: 0.002520] [discriminator loss: 0.038057, acc: 0.976562]\n",
      "Epoch : 26, [adversarial loss: 0.002518] [discriminator loss: 0.041885, acc: 0.968750]\n",
      "Epoch : 27, [adversarial loss: 0.002511] [discriminator loss: 0.047285, acc: 0.937500]\n",
      "Epoch : 28, [adversarial loss: 0.002509] [discriminator loss: 0.047640, acc: 0.960938]\n",
      "Epoch : 29, [adversarial loss: 0.002502] [discriminator loss: 0.037542, acc: 0.953125]\n",
      "Epoch : 30, [adversarial loss: 0.002507] [discriminator loss: 0.043112, acc: 0.984375]\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "model=models(40000)\n",
    "train(model, 1000, 64, 40000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
